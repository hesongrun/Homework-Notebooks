{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import unicodedata\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from secedgar.filings import Filing, FilingType\n",
    "import datetime as dt\n",
    "import bs4 \n",
    "import re\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.63it/s]                        \n"
     ]
    }
   ],
   "source": [
    "my_filings = Filing(cik_lookup = 'aapl', filing_type = FilingType.FILING_10K, \n",
    "                    start_date = dt.datetime(2010,1,1), end_date = dt.datetime(2020,12,31))\n",
    "\n",
    "my_filings.save('Corpus_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.17it/s]                        \n"
     ]
    }
   ],
   "source": [
    "my_filings = Filing(cik_lookup = 'tsla', filing_type = FilingType.FILING_10K, \n",
    "                    start_date = dt.datetime(2010,1,1), end_date = dt.datetime(2020,12,31))\n",
    "\n",
    "my_filings.save('Corpus_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "my_filings = Filing(cik_lookup = 'googl', filing_type = FilingType.FILING_10K, \n",
    "                    start_date = dt.datetime(2010,1,1), end_date = dt.datetime(2020,12,31))\n",
    "\n",
    "my_filings.save('Corpus_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "my_filings = Filing(cik_lookup = 'fb', filing_type = FilingType.FILING_10K, \n",
    "                    start_date = dt.datetime(2010,1,1), end_date = dt.datetime(2020,12,31))\n",
    "\n",
    "my_filings.save('Corpus_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:12,  1.55it/s]                        \n"
     ]
    }
   ],
   "source": [
    "my_filings = Filing(cik_lookup = 'gm', filing_type = FilingType.FILING_10K, \n",
    "                    start_date = dt.datetime(2010,1,1), end_date = dt.datetime(2020,12,31))\n",
    "\n",
    "my_filings.save('Corpus_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:07,  2.70it/s]                        \n"
     ]
    }
   ],
   "source": [
    "my_filings = Filing(cik_lookup = 'msft', filing_type = FilingType.FILING_10K, \n",
    "                    start_date = dt.datetime(2010,1,1), end_date = dt.datetime(2020,12,31))\n",
    "\n",
    "my_filings.save('Corpus_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Normalize Text\n",
    "    \"\"\"\n",
    "    text = unicodedata.normalize(\"NFKD\", text)  # Normalize\n",
    "    text = '\\n'.join(text.splitlines())  # Unicode break lines\n",
    "\n",
    "    # Convert to upper\n",
    "    text = text.upper()  # Convert to upper\n",
    "\n",
    "    # Take care of breaklines & whitespaces combinations due to beautifulsoup parsing\n",
    "    text = re.sub(r'[ ]+\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n[ ]+', '\\n', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # To find MDA section, reformat item headers\n",
    "    text = text.replace('\\n.\\n', '.\\n')  # Move Period to beginning\n",
    "\n",
    "    text = text.replace('\\nI\\nTEM', '\\nITEM')\n",
    "    text = text.replace('\\nITEM\\n', '\\nITEM ')\n",
    "    text = text.replace('\\nITEM  ', '\\nITEM ')\n",
    "\n",
    "    text = text.replace(':\\n', '.\\n')\n",
    "\n",
    "    # Math symbols for clearer looks\n",
    "    text = text.replace('$\\n', '$')\n",
    "    text = text.replace('\\n%', '%')\n",
    "\n",
    "    # Reformat\n",
    "    text = text.replace('\\n', '\\n\\n')  # Reformat by additional breakline\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mda_from_text(text, start=0):\n",
    "    \"\"\"Find MDA (Management Discussion and Analysis) section from normalized text\n",
    "    Args:\n",
    "        text (str)s\n",
    "    \"\"\"\n",
    "    debug = False\n",
    "\n",
    "    mda = \"\"\n",
    "    end = 0\n",
    "\n",
    "    # Define start & end signal for parsing\n",
    "    item7_begins = [\n",
    "        '\\nITEM 7.', '\\nITEM 7 –', '\\nITEM 7:', '\\nITEM 7 ', '\\nITEM 7\\n'\n",
    "    ]\n",
    "    item7_ends = ['\\nITEM 7A']\n",
    "    if start != 0:\n",
    "        item7_ends.append('\\nITEM 7')  # Case: ITEM 7A does not exist\n",
    "    item8_begins = ['\\nITEM 8']\n",
    "    \"\"\"\n",
    "    Parsing code section\n",
    "    \"\"\"\n",
    "    text = text[start:]\n",
    "\n",
    "    # Get begin\n",
    "    for item7 in item7_begins:\n",
    "        begin = text.find(item7)\n",
    "        if debug:\n",
    "            print(item7, begin)\n",
    "        if begin != -1:\n",
    "            break\n",
    "\n",
    "    if begin != -1:  # Begin found\n",
    "        for item7A in item7_ends:\n",
    "            end = text.find(item7A, begin + 1)\n",
    "            if debug:\n",
    "                print(item7A, end)\n",
    "            if end != -1:\n",
    "                break\n",
    "\n",
    "        if end == -1:  # ITEM 7A does not exist\n",
    "            for item8 in item8_begins:\n",
    "                end = text.find(item8, begin + 1)\n",
    "                if debug:\n",
    "                    print(item8, end)\n",
    "                if end != -1:\n",
    "                    break\n",
    "\n",
    "        # Get MDA\n",
    "        if end > begin:\n",
    "            mda = text[begin:end].strip()\n",
    "        else:\n",
    "            end = 0\n",
    "\n",
    "    return mda, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_10k/fb/10-k/0001326801-13-000003.txt\n",
      "Corpus_10k/fb/10-k/0001326801-14-000007.txt\n",
      "Corpus_10k/fb/10-k/0001326801-15-000006.txt\n",
      "Corpus_10k/fb/10-k/0001326801-15-000010.txt\n",
      "Corpus_10k/fb/10-k/0001326801-16-000043.txt\n",
      "Corpus_10k/fb/10-k/0001326801-16-000063.txt\n",
      "Corpus_10k/fb/10-k/0001326801-17-000007.txt\n",
      "Corpus_10k/fb/10-k/0001326801-18-000009.txt\n",
      "Corpus_10k/fb/10-k/0001326801-19-000009.txt\n",
      "Corpus_10k/fb/10-k/0001326801-20-000013.txt\n",
      "Corpus_10k/msft/10-k/0001193125-10-171791.txt\n",
      "Corpus_10k/msft/10-k/0001193125-11-200680.txt\n",
      "Corpus_10k/msft/10-k/0001193125-12-316848.txt\n",
      "Corpus_10k/msft/10-k/0001193125-13-310206.txt\n",
      "Corpus_10k/msft/10-k/0001193125-14-289961.txt\n",
      "Corpus_10k/msft/10-k/0001193125-15-272806.txt\n",
      "Corpus_10k/msft/10-k/0001193125-16-662209.txt\n",
      "Corpus_10k/msft/10-k/0001564590-17-014900.txt\n",
      "Corpus_10k/msft/10-k/0001564590-18-019062.txt\n",
      "Corpus_10k/msft/10-k/0001564590-19-027952.txt\n",
      "Corpus_10k/msft/10-k/0001564590-20-034944.txt\n",
      "Corpus_10k/tsla/10-k/0001193125-11-054847.txt\n",
      "Corpus_10k/tsla/10-k/0001193125-12-081990.txt\n",
      "Corpus_10k/tsla/10-k/0001193125-12-137560.txt\n",
      "Corpus_10k/tsla/10-k/0001193125-13-096241.txt\n",
      "Corpus_10k/tsla/10-k/0001193125-14-069681.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-15-001031.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-16-013195.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-17-003118.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-18-002956.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-19-003165.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-20-004475.txt\n",
      "Corpus_10k/tsla/10-k/0001564590-20-018984.txt\n",
      "Corpus_10k/gm/10-k/0001193125-10-078119.txt\n",
      "Corpus_10k/gm/10-k/0001193125-11-051462.txt\n",
      "Corpus_10k/gm/10-k/0001467858-12-000014.txt\n",
      "Corpus_10k/gm/10-k/0001467858-13-000025.txt\n",
      "Corpus_10k/gm/10-k/0001467858-14-000043.txt\n",
      "Corpus_10k/gm/10-k/0001467858-15-000036.txt\n",
      "Corpus_10k/gm/10-k/0001467858-16-000255.txt\n",
      "Corpus_10k/gm/10-k/0001467858-17-000028.txt\n",
      "Corpus_10k/gm/10-k/0001467858-18-000022.txt\n",
      "Corpus_10k/gm/10-k/0001467858-19-000033.txt\n",
      "Corpus_10k/gm/10-k/0001467858-20-000028.txt\n"
     ]
    }
   ],
   "source": [
    "companies = ['aapl', 'googl', 'fb', 'msft', 'tsla', 'gm']\n",
    "\n",
    "for j in companies[2:]:\n",
    "    company = j\n",
    "\n",
    "    files = glob.glob('Corpus_10k/'+company+'/10-k/*')\n",
    "    files.sort()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i in files:\n",
    "        print(i)\n",
    "        with open(i) as f:\n",
    "            content = f.read()\n",
    "        try:\n",
    "            soup = bs4.BeautifulSoup(content, \"html.parser\")\n",
    "        except TypeError:\n",
    "            continue\n",
    "        text = soup.get_text(\"\\n\")\n",
    "        text = normalize_text(text)\n",
    "        mda, end = find_mda_from_text(text)\n",
    "        if mda and len(mda.encode('utf-8')) < 1000:\n",
    "            mda, _ = find_mda_from_text(text, start=end)\n",
    "        if len(mda.encode('utf-8')) < 1000:\n",
    "            continue\n",
    "        df = df.append(pd.DataFrame({'company': [company], 'filename': [i], 'mda': [mda]}))\n",
    "\n",
    "    df.to_pickle('Corpus_mda/'+company+'_mda.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "0    ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS O...\n",
       "Name: mda, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mda'].apply(lambda x: x.replace('\\n\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
